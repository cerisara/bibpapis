abstract: Predicting the number of citations of scholarly documents is an upcoming
  task in scholarly document processing. Besides the intrinsic merit of this information,
  it also has a wider use as an imperfect proxy for quality which has the advantage
  of being cheaply available for large volumes of scholarly documents. Previous work
  has dealt with number of citations prediction with relatively small training data
  sets, or larger datasets but with short, incomplete input text. In this work we
  leverage the open access ACL Anthology collection in combination with the Semantic
  Scholar bibliometric database to create a large corpus of scholarly documents with
  associated citation information and we propose a new citation prediction model called
  SChuBERT. In our experiments we compare SChuBERT with several state-of-the-art citation
  prediction models and show that it outperforms previous methods by a large margin.
  We also show the merit of using more training data and longer input for number of
  citations prediction.
archiveprefix: arXiv
author: van Dongen, Thomas and de Buy Wenniger, Gideon Maillette and Schomaker, Lambert
author_list:
- family: van Dongen
  given: Thomas
- family: de Buy Wenniger
  given: Gideon Maillette
- family: Schomaker
  given: Lambert
doi: 10.18653/v1/2020.sdp-1.17
eprint: 2012.11740v1
file: 2012.11740v1.pdf
files:
- tmp69zvdjz3.pdf
month: Dec
note: Proceedings of the First Workshop on Scholarly Document   Processing. Association
  for Computational Linguistics. (2020) 158-167.   EMNLP|SDP 2020 https://www.aclweb.org/anthology/2020.sdp-1.17/
primaryclass: cs.CL
ref: 2012.11740v1
time-added: 2022-04-24-12:23:25
title: 'SChuBERT: Scholarly Document Chunks with BERT-encoding boost Citation   Count
  Prediction'
type: article
url: http://arxiv.org/abs/2012.11740v1
year: '2020'
