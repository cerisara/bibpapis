abstract: Continual learning is essential for real-world deployment when there is
  a need to quickly adapt the model to new tasks without forgetting knowledge of old
  tasks. Existing work on continual sequence generation either always reuses existing
  parameters to learn new tasks, which is vulnerable to catastrophic forgetting on
  dissimilar tasks, or blindly adds new parameters for every new task, which could
  prevent knowledge sharing between similar tasks. To get the best of both worlds,
  in this work, we propose continual sequence generation with adaptive compositional
  modules to adaptively add modules in transformer architectures and compose both
  old and new modules for new tasks. We also incorporate pseudo experience replay
  to facilitate knowledge transfer in those shared modules. Experiment results on
  various sequences of generation tasks show that our framework can adaptively add
  modules or reuse modules based on task similarity, outperforming state-of-the-art
  baselines in terms of both performance and parameter efficiency. We make our code
  public at https://github.com/GT-SALT/Adaptive-Compositional-Modules.
archiveprefix: arXiv
author: Zhang, Yanzhe and Wang, Xuezhi and Yang, Diyi
author_list:
- family: Zhang
  given: Yanzhe
- family: Wang
  given: Xuezhi
- family: Yang
  given: Diyi
eprint: 2203.10652v1
file: 2203.10652v1.pdf
files:
- tmpq47d-t40.pdf
month: Mar
primaryclass: cs.CL
ref: 2203.10652v1
time-added: 2022-04-05-09:34:55
title: Continual Sequence Generation with Adaptive Compositional Modules
type: article
url: http://arxiv.org/abs/2203.10652v1
year: '2022'
