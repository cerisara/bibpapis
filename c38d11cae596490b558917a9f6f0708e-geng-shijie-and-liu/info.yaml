abstract: For a long period, different recommendation tasks typically require designing
  task-specific architectures and training objectives. As a result, it is hard to
  transfer the learned knowledge and representations from one task to another, thus
  restricting the generalization ability of existing recommendation approaches, e.g.,
  a sequential recommendation model can hardly be applied or transferred to a review
  generation method. To deal with such issues, considering that language grounding
  is a powerful medium to describe and represent various problems or tasks, we present
  a flexible and unified text-to-text paradigm called "Pretrain, Personalized Prompt,
  and Predict Paradigm" (P5) for recommendation, which unifies various recommendation
  tasks in a shared framework. In P5, all data such as user-item interactions, item
  metadata, and user reviews are converted to a common format -- natural language
  sequences. The rich information from natural language assist P5 to capture deeper
  semantics for recommendation. P5 learns different tasks with the same language modeling
  objective during pretraining. Thus, it possesses the potential to serve as the foundation
  model for downstream recommendation tasks, allows easy integration with other modalities,
  and enables instruction-based recommendation, which will revolutionize the technical
  form of recommender system towards universal recommendation engine. With adaptive
  personalized prompt for different users, P5 is able to make predictions in a zero-shot
  or few-shot manner and largely reduces the necessity for extensive fine-tuning.
  On several recommendation benchmarks, we conduct experiments to show the effectiveness
  of our generative approach. We will release our prompts and pretrained P5 language
  model to help advance future research on Recommendation as Language Processing (RLP)
  and Personalized Foundation Models.
archiveprefix: arXiv
author: Geng, Shijie and Liu, Shuchang and Fu, Zuohui and Ge, Yingqiang and Zhang,
  Yongfeng
author_list:
- family: Geng
  given: Shijie
- family: Liu
  given: Shuchang
- family: Fu
  given: Zuohui
- family: Ge
  given: Yingqiang
- family: Zhang
  given: Yongfeng
eprint: 2203.13366v2
file: 2203.13366v2.pdf
files:
- tmp00udm-s7.pdf
month: Mar
primaryclass: cs.IR
ref: 2203.13366v2
time-added: 2022-04-02-10:57:49
title: 'Recommendation as Language Processing (RLP): A Unified Pretrain,   Personalized
  Prompt & Predict Paradigm (P5)'
type: article
url: http://arxiv.org/abs/2203.13366v2
year: '2022'
