abstract: Few-shot in-context learning (ICL) enables pre-trained language models to
  perform a previously-unseen task without any gradient-based training by feeding
  a small number of training examples as part of the input. ICL incurs substantial
  computational, memory, and storage costs because it involves processing all of the
  training examples every time a prediction is made. Parameter-efficient fine-tuning
  (e.g. adapter modules, prompt tuning, sparse update methods, etc.) offers an alternative
  paradigm where a small set of parameters are trained to enable a model to perform
  the new task. In this paper, we rigorously compare few-shot ICL and parameter-efficient
  fine-tuning and demonstrate that the latter offers better accuracy as well as dramatically
  lower computational costs. Along the way, we introduce a new parameter-efficient
  fine-tuning method called (IA)$^3$ that scales activations by learned vectors, attaining
  stronger performance while only introducing a relatively tiny amount of new parameters.
  We also propose a simple recipe based on the T0 model called T-Few that can be applied
  to new tasks without task-specific tuning or modifications. We validate the effectiveness
  of T-Few on completely unseen tasks by applying it to the RAFT benchmark, attaining
  super-human performance for the first time and outperforming the state-of-the-art
  by 6% absolute. All of the code used in our experiments is publicly available.
archiveprefix: arXiv
author: Liu, Haokun and Tam, Derek and Muqeeth, Mohammed and Mohta, Jay and Huang,
  Tenghao and Bansal, Mohit and Raffel, Colin
author_list:
- family: Liu
  given: Haokun
- family: Tam
  given: Derek
- family: Muqeeth
  given: Mohammed
- family: Mohta
  given: Jay
- family: Huang
  given: Tenghao
- family: Bansal
  given: Mohit
- family: Raffel
  given: Colin
eprint: 2205.05638v1
file: 2205.05638v1.pdf
files:
- tmpep63yexh.pdf
month: May
primaryclass: cs.LG
ref: 2205.05638v1
time-added: 2022-05-12-08:33:03
title: Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than   In-Context
  Learning
type: article
url: http://arxiv.org/abs/2205.05638v1
year: '2022'
