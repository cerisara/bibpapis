abstract: Evolution strategies (ES) are a family of black-box optimization algorithms
  able to train deep neural networks roughly as well as Q-learning and policy gradient
  methods on challenging deep reinforcement learning (RL) problems, but are much faster
  (e.g. hours vs. days) because they parallelize better. However, many RL problems
  require directed exploration because they have reward functions that are sparse
  or deceptive (i.e. contain local optima), and it is unknown how to encourage such
  exploration with ES. Here we show that algorithms that have been invented to promote
  directed exploration in small-scale evolved neural networks via populations of exploring
  agents, specifically novelty search (NS) and quality diversity (QD) algorithms,
  can be hybridized with ES to improve its performance on sparse or deceptive deep
  RL tasks, while retaining scalability. Our experiments confirm that the resultant
  new algorithms, NS-ES and two QD algorithms, NSR-ES and NSRA-ES, avoid local optima
  encountered by ES to achieve higher performance on Atari and simulated robots learning
  to walk around a deceptive trap. This paper thus introduces a family of fast, scalable
  algorithms for reinforcement learning that are capable of directed exploration.
  It also adds this new family of exploration algorithms to the RL toolbox and raises
  the interesting possibility that analogous algorithms with multiple simultaneous
  paths of exploration might also combine well with existing RL algorithms outside
  ES.
address: Red Hook, NY, USA
author: Conti, Edoardo and Madhavan, Vashisht and Such, Felipe Petroski and Lehman,
  Joel and Stanley, Kenneth O. and Clune, Jeff
author_list:
- family: Conti
  given: Edoardo
- family: Madhavan
  given: Vashisht
- family: Such
  given: Felipe Petroski
- family: Lehman
  given: Joel
- family: Stanley
  given: Kenneth O.
- family: Clune
  given: Jeff
booktitle: Proceedings of the 32nd International Conference on Neural Information
  Processing Systems
files:
- tt.data
location: Montr\'{e}al, Canada
numpages: '12'
pages: 5032â€“5043
publisher: Curran Associates Inc.
ref: 10.5555/3327345.3327410
series: NIPS'18
time-added: 2022-04-19-21:20:44
title: Improving Exploration in Evolution Strategies for Deep Reinforcement Learning
  via a Population of Novelty-Seeking Agents
type: inproceedings
year: '2018'
